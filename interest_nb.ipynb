{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"AAPL\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Get the stock data\n",
    "data_aapl = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the stock data\n",
    "print(data_aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aapl = data_aapl.drop(columns=data_aapl.columns.difference(['Adj Close']))\n",
    "print(data_aapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the S&P 500 constituents from Wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "df = pd.read_html(url)[0]\n",
    "\n",
    "# Extract the ticker symbols\n",
    "sp500_tickers = df[\"Symbol\"].tolist()\n",
    "\n",
    "# Convert the list to a Python string\n",
    "sp500_tickers_string = \", \".join(sp500_tickers)\n",
    "\n",
    "# Print the result\n",
    "print(sp500_tickers_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"MSFT\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Get the stock data\n",
    "data_msft = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the stock data\n",
    "print(data_msft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_msft = data_msft.drop(columns=data_msft.columns.difference(['Adj Close']))\n",
    "print(data_msft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the data for AAPL and MSFT\n",
    "data_combined = pd.concat([data_aapl['Adj Close'], data_msft['Adj Close']], axis=1)\n",
    "\n",
    "print(data_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"MSFT\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Get the stock data\n",
    "data_tsla = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the stock data\n",
    "# print(data_msft)\n",
    "\n",
    "data_tsla = data_tsla.drop(columns=data_tsla.columns.difference(['Adj Close']))\n",
    "print(data_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined['TSLA'] = data_tsla['Adj Close']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in sp500_tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data = data.drop(columns=data.columns.difference(['Adj Close']))\n",
    "    data_combined[ticker] = data['Adj Close']\n",
    "\n",
    "print(data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined.to_csv('sp500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"AAPL\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"1980-12-12\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Get the stock data\n",
    "data_aapl = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the stock data\n",
    "print(data_aapl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# List of S&P 500 tickers\n",
    "sp500_tickers = [ticker for ticker in sp500_tickers if ticker not in ['BRK.B', 'BF.B']]\n",
    "\n",
    "data = []\n",
    "\n",
    "for ticker in sp500_tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist = stock.history(period=\"max\")\n",
    "    start_date = hist.index[0]\n",
    "    data.append([ticker, start_date])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Ticker', 'Start_Date'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = df['Start_Date'].min()\n",
    "print(earliest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = {}\n",
    "adj_close_df = pd.DataFrame()\n",
    "end_date = \"2023-12-31\"\n",
    "for index, row in df.head(10).iterrows():\n",
    "    ticker = row['Ticker']\n",
    "    start_date = row['Start_Date']\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data = data.drop(columns=data.columns.difference(['Adj Close']))\n",
    "    adj_close_df = adj_close_df.append(data)\n",
    "\n",
    "matrix = adj_close_df.pivot_table(values='Adj Close', index=adj_close_df.index, columns='Ticker')\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data = {}\n",
    "# adj_close_df = pd.DataFrame()\n",
    "start_date = \"1962-01-02\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "date_list = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame\n",
    "matrix = pd.DataFrame(index=sp500_tickers, columns=date_list)\n",
    "\n",
    "# Print the matrix\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in sp500_tickers:\n",
    "    start_date = pd.Timestamp(df[df['Ticker'] == ticker]['Start_Date'].values[0])\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data = data.drop(columns=data.columns.difference(['Adj Close']))\n",
    "    matrix.loc[ticker] = data['Adj Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.transpose()\n",
    "matrix.to_csv('sp500_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv('sp500_matrix.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"NESN.SW\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "# Get the stock data\n",
    "data_nesn = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the stock data\n",
    "print(data_nesn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_tickers = ['NESN.SW', 'ROG.SW', 'NOVN.SW', 'CFR.SW', 'ZURN.SW', 'UBSG.SW', 'ABBN.SW', 'LONN.SW', 'SIKA.SW', 'ALC.SW', 'GIVN.SW', 'HOLN.SW', 'SCMN.SW', 'PGHN.SW', 'SREN.SW', 'SOON.SW', 'GEBN.SW', 'SLHN.SW', 'LOGN.SW', 'KNIN.SW'] \n",
    "\n",
    "smi_data_combined = pd.DataFrame()\n",
    "\n",
    "for ticker in smi_tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data = data.drop(columns=data.columns.difference(['Adj Close']))\n",
    "    smi_data_combined[ticker] = data['Adj Close']\n",
    "\n",
    "print(smi_data_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for ticker in smi_tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist = stock.history(period=\"max\")\n",
    "    start_date = hist.index[0]\n",
    "    data.append([ticker, start_date])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Ticker', 'Start_Date'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = df['Start_Date'].min()\n",
    "print(earliest_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data = {}\n",
    "# adj_close_df = pd.DataFrame()\n",
    "start_date = \"1990-01-03\"\n",
    "end_date = \"2023-12-31\"\n",
    "\n",
    "date_list = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame\n",
    "smi_matrix = pd.DataFrame(index=smi_tickers, columns=date_list)\n",
    "\n",
    "for ticker in smi_tickers:\n",
    "    start_date = pd.Timestamp(df[df['Ticker'] == ticker]['Start_Date'].values[0])\n",
    "    data = yf.download(ticker, start=start_date, end=end_date)\n",
    "    data = data.drop(columns=data.columns.difference(['Adj Close']))\n",
    "    smi_matrix.loc[ticker] = data['Adj Close']\n",
    "\n",
    "print(smi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the date threshold\n",
    "threshold_date = pd.Timestamp('2000-01-01')\n",
    "\n",
    "# Remove columns where the value is less than the threshold date\n",
    "smi_matrix = smi_matrix.drop(columns=smi_matrix.columns[smi_matrix.columns < threshold_date])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(smi_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column names to Timestamp objects\n",
    "matrix.columns = pd.to_datetime(matrix.columns)\n",
    "\n",
    "# Remove columns where the value is less than the threshold date\n",
    "matrix = matrix.drop(columns=matrix.columns[matrix.columns < threshold_date])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_matrix.to_csv('smi_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_matrix = pd.read_csv('smi_matrix.csv', index_col=0, parse_dates=True)\n",
    "smi_matrix = smi_matrix.transpose()\n",
    "smi_matrix.to_csv('smi_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data = pd.read_excel('API_USA_DS2_en_excel_v2_820.xls', index_col=0, sheet_name='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(us_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "rate_swiss = [4.00, 2.25, 1.25, 0.75, 1.25, 1.50, 2.50, 3.25, 1.00, 0.75, 0.75, 0.25, 0.25, 0.25, 0.25, -0.25, -0.25, -0.25, -0.25, -0.75, -0.75, -0.75, 1.00, 1.75]\n",
    "\n",
    "# Create a DataFrame for rate_swiss\n",
    "df_rate_swiss = pd.DataFrame(rate_swiss, columns=['rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rate_us = [6.50, 1.75, 1.25, 1.00, 2.25, 4.25, 5.25, 4.25, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.38, 0.63, 1.38, 2.38, 1.63, 0.13, 0.13, 4.38]\n",
    "# Generate a range of dates from \"2000-01-01\" to \"2022-12-31\"\n",
    "dates = pd.date_range(start=\"2000-01-01\", end=\"2022-12-31\", freq='Q')\n",
    "\n",
    "# Create a DataFrame with rate_us as values and dates as index\n",
    "df_us = pd.DataFrame(rate_us, index=dates, columns=['Rate'])\n",
    "\n",
    "print(df_us)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_swiss = [3.50, 4.00, 4.00, 4.00, 3.75, 3.75, 2.75, 2.25, 2.25, 1.75, 1.25, 1.25, 0.75, 0.75, 0.75, 0.75, 0.75, 1.00, 1.25, 1.25, 1.25, 1.25, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.25, 3.25, 3.25, 3.25, 1.00, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.25, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.75, -0.25, 0.50, 1.00]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_us = [6.00, 6.50, 6.50, 6.50, 5.31, 3.97, 3.27, 1.75, 1.75, 1.75, 1.75, 1.25, 1.25, 1.00, 1.00, 1.00, 1.00, 1.25, 1.75, 2.25, 2.75, 3.25, 3.75, 4.25, 4.75, 5.25, 5.25, 5.25, 5.25, 5.25, 4.75, 4.25, 2.25, 2.00, 2.00, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.38, 0.38, 0.38, 0.38, 0.63, 0.88, 1.13, 1.13, 1.38, 1.63, 1.88, 2.13, 2.38, 2.38, 2.38, 1.88, 1.63, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.38, 1.63, 3.13, 4.38]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start=\"2000-01-01\", end=\"2022-12-31\", freq='Q')\n",
    "\n",
    "# Create a DataFrame with rate_us as values and dates as index\n",
    "df_swiss = pd.DataFrame(values_swiss, index=dates, columns=['Rate'])\n",
    "df_us = pd.DataFrame(values_us, index=dates, columns=['Rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is your original DataFrame\n",
    "start_date = df_us.index.min().to_period('Q').start_time\n",
    "end_date = df_us.index.max()\n",
    "new_index = pd.date_range(start_date, end_date, freq='D')\n",
    "df_daily_us = df_us.reindex(new_index).bfill().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is your original DataFrame\n",
    "start_date = df_swiss.index.min().to_period('Q').start_time\n",
    "end_date = df_swiss.index.max()\n",
    "new_index = pd.date_range(start_date, end_date, freq='D')\n",
    "df_daily_swiss = df_swiss.reindex(new_index).bfill().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_daily_us.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rate_swiss = [4.00, 2.25, 1.25, 0.75, 1.25, 1.50, 2.50, 3.25, 1.00, 0.75, 0.75, 0.25, 0.25, 0.25, 0.25, -0.25, -0.25, -0.25, -0.25, -0.75, -0.75, -0.75, 1.00]\n",
    "df_swiss = pd.DataFrame(rate_swiss)\n",
    "\n",
    "# Create a DataFrame with rate_us as values and dates as index\n",
    "df_swiss = pd.DataFrame(rate_swiss, index=dates, columns=['Rate'])\n",
    "\n",
    "print(df_swiss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker = \"MSFT\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2022-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "# Get the stock data\n",
    "data_msft = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Calculate the daily returns\n",
    "data_msft['Daily Returns'] = data_msft['Adj Close'].pct_change()\n",
    "\n",
    "# Calculate the volatility\n",
    "volatility = data_msft['Daily Returns'].std()\n",
    "\n",
    "# Print the volatility\n",
    "print(\"Volatility of Microsoft stock for the past year:\", volatility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_1 = pd.read_csv('Switzerland 1-Year Bond Yield Historical Data.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_2 = pd.read_csv('Switzerland 1-Year Bond Yield Historical Data_2.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_bonds = pd.concat([swiss_2, swiss_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_bonds.to_csv('swiss_bonds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_bonds = pd.read_csv('swiss_bonds.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swiss_bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_bonds = pd.read_csv(\"DGS1.csv\", index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_bonds.fillna(method='bfill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol for S&P 500\n",
    "ticker = \"^GSPC\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "# Get the S&P 500 data\n",
    "data_sp500 = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the S&P 500 data\n",
    "print(data_sp500)\n",
    "data_sp500 = data_sp500.drop(columns=data_sp500.columns.difference(['Adj Close']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol for SMI\n",
    "ticker = \"^SSMI\"\n",
    "\n",
    "# Define the start and end dates\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2022-12-31\"\n",
    "\n",
    "# Get the SMI data\n",
    "data_smi = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "# Print the SMI data\n",
    "print(data_smi)\n",
    "data_smi = data_smi.drop(columns=data_smi.columns.difference(['Adj Close']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_swiss = df_daily_swiss.join(data_smi, how='inner').join(swiss_bonds, how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined_swiss.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_us = df_daily_us.join(data_sp500, how='inner').join(us_bonds, how='inner')\n",
    "print(df_combined_us.to_string()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_us.to_csv('us_combined.csv')\n",
    "df_combined_swiss.to_csv('swiss_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_us = pd.read_csv('us_combined.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_us = df_combined_us.join(matrix, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined_us.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_swiss = pd.read_csv('swiss_combined.csv', index_col=0, parse_dates=True)\n",
    "df_combined_swiss = df_combined_swiss.join(smi_matrix, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined_swiss.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_us.to_csv('us_combined.csv')\n",
    "df_combined_swiss.to_csv('swiss_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data = pd.read_excel('API_USA_DS2_en_excel_v2_820.xls', index_col=0, sheet_name='Data')\n",
    "swiss_data = pd.read_excel('API_CHE_DS2_en_excel_v2_16891.xls', index_col=0, sheet_name='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined_us and df_combined_swiss are your original DataFrames\n",
    "us_columns = df_combined_us[['interest_rate', 'mkt_index', 'bond_yield']]\n",
    "swiss_columns = df_combined_swiss[['interest_rate', 'mkt_index', 'bond_yield']]\n",
    "\n",
    "# Concatenate the selected columns\n",
    "df_combined = pd.concat([us_columns, swiss_columns], axis=1)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_combined.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_swiss = pd.read_csv('swiss_combined.csv', index_col=0, parse_dates=True)\n",
    "df_combined_us = pd.read_csv('us_combined.csv', index_col=0, parse_dates=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df is your original DataFrame\n",
    "df_combined_swiss = df_combined_swiss.reset_index().drop_duplicates(subset='index')\n",
    "df_combined_swiss = df_combined_swiss.rename(columns={'index': 'Date'})\n",
    "df_combined_swiss = df_combined_swiss.set_index('Date')\n",
    "df_combined_us = df_combined_us.reset_index().drop_duplicates(subset='index')\n",
    "df_combined_us = df_combined_us.rename(columns={'index': 'Date'})\n",
    "df_combined_us = df_combined_us.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined_swiss.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_combined = df_combined_us.join(df_combined_swiss, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all_combined.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = df_all_combined[['us_interest_rate', 'us_mkt_index', 'us_bond_yield', 'swiss_interest_rate', 'swiss_mkt_index', 'swiss_bond_yield']]\n",
    "# Convert string values to numeric values, replacing non-numeric values with NaN\n",
    "df_core = df_core.apply(pd.to_numeric, errors='coerce')\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_core.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set the style of the correlation matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "correlation_heatmap = correlation_matrix.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# Display the correlation heatmap\n",
    "correlation_heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, figsize=(12, 18))\n",
    "\n",
    "# Scatter plot for interest rates\n",
    "axs[0].scatter(df_core['us_interest_rate'], df_core['swiss_interest_rate'])\n",
    "axs[0].set_xlabel('US Interest Rate')\n",
    "axs[0].set_ylabel('Swiss Interest Rate')\n",
    "\n",
    "# Scatter plot for market indexes\n",
    "axs[1].scatter(df_core['us_mkt_index'], df_core['swiss_mkt_index'])\n",
    "axs[1].set_xlabel('US Market Index')\n",
    "axs[1].set_ylabel('Swiss Market Index')\n",
    "\n",
    "# Scatter plot for bond yields\n",
    "axs[2].scatter(df_core['us_bond_yield'], df_core['swiss_bond_yield'])\n",
    "axs[2].set_xlabel('US Bond Yield')\n",
    "axs[2].set_ylabel('Swiss Bond Yield')\n",
    "\n",
    "plt.suptitle('Scatter Plots of US and Swiss Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert the index to datetime with dayfirst=True\n",
    "df_core.index = pd.to_datetime(df_core.index, dayfirst=True)\n",
    "\n",
    "fig, axs = plt.subplots(3, figsize=(12, 18))\n",
    "\n",
    "# Time series plot for interest rates\n",
    "axs[0].plot(df_core.index, df_core['us_interest_rate'], label='US Interest Rate')\n",
    "axs[0].plot(df_core.index, df_core['swiss_interest_rate'], label='Swiss Interest Rate')\n",
    "axs[0].set_ylabel('Interest Rate')\n",
    "axs[0].legend()\n",
    "\n",
    "# Time series plot for market indexes\n",
    "axs[1].plot(df_core.index, df_core['us_mkt_index'], label='US Market Index')\n",
    "axs[1].plot(df_core.index, df_core['swiss_mkt_index'], label='Swiss Market Index')\n",
    "axs[1].set_ylabel('Market Index')\n",
    "axs[1].legend()\n",
    "\n",
    "# Time series plot for bond yields\n",
    "axs[2].plot(df_core.index, df_core['us_bond_yield'], label='US Bond Yield')\n",
    "axs[2].plot(df_core.index, df_core['swiss_bond_yield'], label='Swiss Bond Yield')\n",
    "axs[2].set_xlabel('Date')\n",
    "axs[2].set_ylabel('Bond Yield')\n",
    "axs[2].legend()\n",
    "\n",
    "# Format the x-axis to display less frequent ticks\n",
    "years = mdates.YearLocator()   # every year\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "plt.suptitle('Time Series Plot of US and Swiss Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histograms for each column in df_core\n",
    "df_core.hist(figsize=(12, 8))\n",
    "plt.suptitle('Histograms of Variables in df_core')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_combined.to_csv('all_combined.csv')\n",
    "df_core.to_csv('core.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "result_adf = adfuller(data, regression='c')\n",
    "adf_statistic = result_adf[0]\n",
    "adf_pvalue = result_adf[1]\n",
    "adf_critical_values = result_adf[4]\n",
    "\n",
    "# Perform KPSS test\n",
    "result_kpss = kpss(data, regression='c')\n",
    "kpss_statistic = result_kpss[0]\n",
    "kpss_pvalue = result_kpss[1]\n",
    "kpss_critical_values = result_kpss[3]\n",
    "\n",
    "# Print the test results\n",
    "print(\"Augmented Dickey-Fuller Test:\")\n",
    "print(f\"ADF Statistic: {adf_statistic}\")\n",
    "print(f\"ADF p-value: {adf_pvalue}\")\n",
    "print(\"ADF Critical Values:\")\n",
    "for key, value in adf_critical_values.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nKPSS Test:\")\n",
    "print(f\"KPSS Statistic: {kpss_statistic}\")\n",
    "print(f\"KPSS p-value: {kpss_pvalue}\")\n",
    "print(\"KPSS Critical Values:\")\n",
    "for key, value in kpss_critical_values.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate the Z-scores\n",
    "df_core_zscore = df_core.apply(zscore)\n",
    "\n",
    "# Identify outliers\n",
    "outliers_zscore = df_core_zscore[(df_core_zscore > 3).any(axis=1)]\n",
    "print(outliers_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR\n",
    "Q1 = df_core.quantile(0.25)\n",
    "Q3 = df_core.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers\n",
    "outliers_iqr = df_core[((df_core < (Q1 - 1.5 * IQR)) | (df_core > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(outliers_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Initialize the Isolation Forest model with an imputer transformer\n",
    "clf = make_pipeline(SimpleImputer(), IsolationForest(contamination=0.01))\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(df_core)\n",
    "\n",
    "# Predict the outliers\n",
    "outliers_if = clf.predict(df_core) == -1    \n",
    "print(df_core[outliers_if])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_data = pd.read_excel('API_USA_DS2_en_excel_v2_820.xls', index_col=0, sheet_name='Data')\n",
    "swiss_data = pd.read_excel('API_CHE_DS2_en_excel_v2_16891.xls', index_col=0, sheet_name='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(us_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_filtered = us_data[us_data['Indicator Code'].isin(['SP.POP.GROW', 'NY.GDP.MKTP.KD.ZG', 'FP.CPI.TOTL', 'SL.UEM.TOTL.NE.ZS', 'GC.DOD.TOTL.GD.ZS', 'BN.CAB.XOKA.GD.ZS'])]\n",
    "swiss_filtered = swiss_data[swiss_data['Indicator Code'].isin(['SP.POP.GROW', 'NY.GDP.MKTP.KD.ZG', 'FP.CPI.TOTL', 'SL.UEM.TOTL.NE.ZS', 'GC.DOD.TOTL.GD.ZS', 'BN.CAB.XOKA.GD.ZS'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_filtered.to_csv('us_filtered.csv')\n",
    "swiss_filtered.to_csv('swiss_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = pd.read_csv('core.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_filtered = pd.read_csv('us_filtered.csv', index_col=0, parse_dates=True)\n",
    "swiss_filtered = pd.read_csv('swiss_filtered.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_filtered.transpose().to_csv('us_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_filtered.transpose().to_csv('swiss_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to datetime\n",
    "us_filtered.index = pd.to_datetime(us_filtered.index)\n",
    "\n",
    "# Resample the data to daily frequency\n",
    "us_filtered_daily = us_filtered.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index to datetime\n",
    "swiss_filtered.index = pd.to_datetime(swiss_filtered.index)\n",
    "\n",
    "# Resample the data to daily frequency\n",
    "swiss_filtered_daily = swiss_filtered.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss_filtered_daily.to_csv('swiss_filtered_daily.csv')\n",
    "us_filtered_daily.to_csv('us_filtered_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core = pd.read_csv('core.csv', index_col=0, parse_dates=True)\n",
    "us_filtered_daily = pd.read_csv('us_filtered_daily.csv', index_col=0, parse_dates=True)\n",
    "swiss_filtered_daily = pd.read_csv('swiss_filtered_daily.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge us_filtered_daily with df_core\n",
    "df_core = df_core.merge(us_filtered_daily, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Merge swiss_filtered_daily with df_core\n",
    "# df_core = df_core.merge(swiss_filtered_daily, how='left', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_core.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core.to_csv('core.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_core.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Set the style of the correlation matrix\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "correlation_heatmap = correlation_matrix.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# Display the correlation heatmap\n",
    "correlation_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create histograms for each column in df_core\n",
    "df_core.hist(figsize=(12, 12))\n",
    "plt.suptitle('Histograms of Variables in df_core')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(9, figsize=(12, 36))\n",
    "\n",
    "# Scatter plot for interest rates\n",
    "axs[0].scatter(df_core['us_interest_rate'], df_core['swiss_interest_rate'])\n",
    "axs[0].set_xlabel('US Interest Rate')\n",
    "axs[0].set_ylabel('Swiss Interest Rate')\n",
    "\n",
    "# Scatter plot for market indexes\n",
    "axs[1].scatter(df_core['us_mkt_index'], df_core['swiss_mkt_index'])\n",
    "axs[1].set_xlabel('US Market Index')\n",
    "axs[1].set_ylabel('Swiss Market Index')\n",
    "\n",
    "# Scatter plot for bond yields\n",
    "axs[2].scatter(df_core['us_bond_yield'], df_core['swiss_bond_yield'])\n",
    "axs[2].set_xlabel('US Bond Yield')\n",
    "axs[2].set_ylabel('Swiss Bond Yield')\n",
    "\n",
    "# Scatter plot for population growth\n",
    "axs[3].scatter(df_core['us_pop_growth'], df_core['swiss_pop_growth'])\n",
    "axs[3].set_xlabel('US Population Growth')\n",
    "axs[3].set_ylabel('Swiss Population Growth')\n",
    "\n",
    "# Scatter plot for GDP growth\n",
    "axs[4].scatter(df_core['us_gdp_growth'], df_core['swiss_gdp_growth'])\n",
    "axs[4].set_xlabel('US GDP Growth')\n",
    "axs[4].set_ylabel('Swiss GDP Growth')\n",
    "\n",
    "# Scatter plot for inflation\n",
    "axs[5].scatter(df_core['us_cpi'], df_core['swiss_cpi'])\n",
    "axs[5].set_xlabel('US Inflation')\n",
    "axs[5].set_ylabel('Swiss Inflation')\n",
    "\n",
    "# Scatter plot for unemployment\n",
    "axs[6].scatter(df_core['us_unemp'], df_core['swiss_unemp'])\n",
    "axs[6].set_xlabel('US Unemployment')\n",
    "axs[6].set_ylabel('Swiss Unemployment')\n",
    "\n",
    "# Scatter plot for government debt\n",
    "axs[7].scatter(df_core['us_debt'], df_core['swiss_debt'])\n",
    "axs[7].set_xlabel('US Government Debt')\n",
    "axs[7].set_ylabel('Swiss Government Debt')\n",
    "\n",
    "# Scatter plot for current account balance\n",
    "axs[8].scatter(df_core['us_current_ac'], df_core['swiss_current_ac'])\n",
    "axs[8].set_xlabel('US Current Account Balance')\n",
    "axs[8].set_ylabel('Swiss Current Account Balance')\n",
    "\n",
    "\n",
    "plt.suptitle('Scatter Plots of US and Swiss Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convert the index to datetime with dayfirst=True\n",
    "df_core.index = pd.to_datetime(df_core.index, dayfirst=True)\n",
    "\n",
    "fig, axs = plt.subplots(9, figsize=(12, 36))\n",
    "\n",
    "# Time series plot for interest rates\n",
    "axs[0].plot(df_core.index, df_core['us_interest_rate'], label='US Interest Rate')\n",
    "axs[0].plot(df_core.index, df_core['swiss_interest_rate'], label='Swiss Interest Rate')\n",
    "axs[0].set_ylabel('Interest Rate')\n",
    "axs[0].legend()\n",
    "\n",
    "# Time series plot for market indexes\n",
    "axs[1].plot(df_core.index, df_core['us_mkt_index'], label='US Market Index')\n",
    "axs[1].plot(df_core.index, df_core['swiss_mkt_index'], label='Swiss Market Index')\n",
    "axs[1].set_ylabel('Market Index')\n",
    "axs[1].legend()\n",
    "\n",
    "# Time series plot for bond yields\n",
    "axs[2].plot(df_core.index, df_core['us_bond_yield'], label='US Bond Yield')\n",
    "axs[2].plot(df_core.index, df_core['swiss_bond_yield'], label='Swiss Bond Yield')\n",
    "axs[2].set_ylabel('Bond Yield')\n",
    "axs[2].legend()\n",
    "\n",
    "# Time series plot for population growth\n",
    "axs[3].plot(df_core.index, df_core['us_pop_growth'], label='US Population Growth')\n",
    "axs[3].plot(df_core.index, df_core['swiss_pop_growth'], label='Swiss Population Growth')\n",
    "axs[3].set_ylabel('Population Growth')\n",
    "axs[3].legend()\n",
    "\n",
    "# Time series plot for GDP growth\n",
    "axs[4].plot(df_core.index, df_core['us_gdp_growth'], label='US GDP Growth')\n",
    "axs[4].plot(df_core.index, df_core['swiss_gdp_growth'], label='Swiss GDP Growth')\n",
    "axs[4].set_ylabel('GDP Growth')\n",
    "axs[4].legend()\n",
    "\n",
    "# Time series plot for inflation\n",
    "axs[5].plot(df_core.index, df_core['us_cpi'], label='US Inflation')\n",
    "axs[5].plot(df_core.index, df_core['swiss_cpi'], label='Swiss Inflation')\n",
    "axs[5].set_ylabel('Inflation')\n",
    "axs[5].legend()\n",
    "\n",
    "# Time series plot for unemployment\n",
    "axs[6].plot(df_core.index, df_core['us_unemp'], label='US Unemployment')\n",
    "axs[6].plot(df_core.index, df_core['swiss_unemp'], label='Swiss Unemployment')\n",
    "axs[6].set_ylabel('Unemployment')\n",
    "axs[6].legend()\n",
    "\n",
    "# Time series plot for government debt\n",
    "axs[7].plot(df_core.index, df_core['us_debt'], label='US Government Debt')\n",
    "axs[7].plot(df_core.index, df_core['swiss_debt'], label='Swiss Government Debt')\n",
    "axs[7].set_ylabel('Government Debt')\n",
    "axs[7].legend()\n",
    "\n",
    "# Time series plot for current account balance\n",
    "axs[8].plot(df_core.index, df_core['us_current_ac'], label='US Current Account Balance')\n",
    "axs[8].plot(df_core.index, df_core['swiss_current_ac'], label='Swiss Current Account Balance')\n",
    "axs[8].set_ylabel('Current Account Balance')\n",
    "axs[8].set_xlabel('Date')\n",
    "axs[8].legend()\n",
    "\n",
    "# Format the x-axis to display less frequent ticks\n",
    "years = mdates.YearLocator()   # every year\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(years)\n",
    "    ax.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "plt.suptitle('Time Series Plot of US and Swiss Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_matrix = pd.read_csv('smi_matrix.csv', index_col=0, parse_dates=True)\n",
    "df_core = pd.read_csv('core.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Merge the data\n",
    "df_swiss_eq = df_core.merge(smi_matrix, how='left', left_index=True, right_index=True).dropna()\n",
    "df_swiss_eq.index = pd.to_datetime(df_swiss_eq.index, dayfirst=True)\n",
    "\n",
    "# List of equities\n",
    "equities = smi_matrix.columns\n",
    "\n",
    "# df_swiss_eq = df_swiss_eq.drop(['swiss_mkt_index', 'us_mkt_index'], axis=1)\n",
    "\n",
    "# Define the independent variables\n",
    "X = df_swiss_eq[df_swiss_eq.columns.difference(equities)]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Run a separate regression model for each equity\n",
    "for equity in equities:\n",
    "    # Define the dependent variable\n",
    "    y = df_swiss_eq[equity]\n",
    "\n",
    "    # Ensure that the index is a DatetimeIndex\n",
    "    # y.index = pd.to_datetime(y.index, dayfirst=True)\n",
    "\n",
    "    # Run the regression model\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # # Plotting the OLS results\n",
    "    # fig, axs = plt.subplots(figsize=(10, 6))\n",
    "    # axs.plot(results.fittedvalues.index, results.fittedvalues, label='Fitted Values')\n",
    "    # axs.plot(y.index, y, label='Actual Values')\n",
    "    # axs.set_xlabel('Date')\n",
    "\n",
    "    # # Format the x-axis to display less frequent ticks\n",
    "    # years = mdates.YearLocator()   # every year\n",
    "    # years_fmt = mdates.DateFormatter('%Y')\n",
    "    # axs.xaxis.set_major_locator(years)\n",
    "    # axs.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "    # axs.legend()\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.title('OLS Results')\n",
    "    # plt.show()\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Results for {equity}:')\n",
    "    print(results.summary())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting the OLS results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(results.fittedvalues, label='Fitted Values')\n",
    "# plt.plot(y, label='Actual Values')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('OLS Results')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the correlation matrix between equities and indicators\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Calculate the average correlation for each indicator\n",
    "average_correlation = correlation_matrix.mean()\n",
    "\n",
    "# Sort the indicators based on average correlation\n",
    "sorted_indicators = average_correlation.sort_values(ascending=False)\n",
    "\n",
    "# Select the top five indicators\n",
    "top_indicators = sorted_indicators[:5]\n",
    "\n",
    "# Get the names of the top indicators\n",
    "top_indicator_names = top_indicators.index.tolist()\n",
    "\n",
    "# Print the top indicators\n",
    "print(\"The five most reliable indicators for all 20 equities are:\")\n",
    "for indicator in top_indicator_names:\n",
    "    print(indicator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Merge the data\n",
    "df_swiss_eq = df_core.merge(smi_matrix, how='left', left_index=True, right_index=True).dropna()\n",
    "df_swiss_eq.index = pd.to_datetime(df_swiss_eq.index, dayfirst=True)\n",
    "\n",
    "# List of equities\n",
    "equities = smi_matrix.columns\n",
    "\n",
    "df_swiss_eq = df_swiss_eq.drop(['swiss_mkt_index', 'us_mkt_index'], axis=1)\n",
    "\n",
    "# Define the independent variables\n",
    "X = df_swiss_eq[df_swiss_eq.columns.difference(equities)]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Run a separate regression model for each equity\n",
    "for equity in equities:\n",
    "    # Define the dependent variable\n",
    "    y = df_swiss_eq[equity]\n",
    "\n",
    "    # Ensure that the index is a DatetimeIndex\n",
    "    # y.index = pd.to_datetime(y.index, dayfirst=True)\n",
    "\n",
    "    # Run the regression model\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # # Plotting the OLS results\n",
    "    # fig, axs = plt.subplots(figsize=(10, 6))\n",
    "    # axs.plot(results.fittedvalues.index, results.fittedvalues, label='Fitted Values')\n",
    "    # axs.plot(y.index, y, label='Actual Values')\n",
    "    # axs.set_xlabel('Date')\n",
    "\n",
    "    # # Format the x-axis to display less frequent ticks\n",
    "    # years = mdates.YearLocator()   # every year\n",
    "    # years_fmt = mdates.DateFormatter('%Y')\n",
    "    # axs.xaxis.set_major_locator(years)\n",
    "    # axs.xaxis.set_major_formatter(years_fmt)\n",
    "\n",
    "    # axs.legend()\n",
    "    # plt.ylabel('Value')\n",
    "    # plt.title('OLS Results')\n",
    "    # plt.show()\n",
    "\n",
    "    # Print the results\n",
    "    print(f'Results for {equity}:')\n",
    "    print(results.summary())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the correlation matrix between equities and indicators\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Calculate the average correlation for each indicator\n",
    "average_correlation = correlation_matrix.mean()\n",
    "\n",
    "# Sort the indicators based on average correlation\n",
    "sorted_indicators = average_correlation.sort_values(ascending=False)\n",
    "\n",
    "# Select the top five indicators\n",
    "top_indicators = sorted_indicators[:5]\n",
    "\n",
    "# Get the names of the top indicators\n",
    "top_indicator_names = top_indicators.index.tolist()\n",
    "\n",
    "# Print the top indicators\n",
    "print(\"The five most reliable indicators for all 20 equities are:\")\n",
    "for indicator in top_indicator_names:\n",
    "    print(indicator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
